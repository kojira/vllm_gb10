services:
  unified-proxy:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: unified-llm-proxy
    restart: unless-stopped
    shm_size: 16g
    ipc: host
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      # モデルを永続化するためのボリューム
      - ./models:/workspace/models
      # Hugging Faceキャッシュ
      - ./.cache:/root/.cache
      # フロントエンド（開発時に即座に反映）
      - ./frontend:/workspace/frontend
      # サーバーコード（開発時に即座に反映）
      - ./proxy_server.py:/workspace/proxy_server.py
      # スクリプト（開発時に即座に反映）
      - ./scripts:/workspace/scripts
    ports:
      - "8080:8080"
    # 統合プロキシサーバーを起動（開発時は--reloadで自動リロード）
    # WATCHFILES_FORCE_POLLING=trueでDockerボリュームマウントでもファイル変更を検知
    command: >
      /bin/bash -c "WATCHFILES_FORCE_POLLING=true uvicorn proxy_server:app --host 0.0.0.0 --port 8080 --reload"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
