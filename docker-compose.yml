services:
  unified-proxy:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: unified-llm-proxy
    restart: unless-stopped
    shm_size: 16g
    ipc: host
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      # モデルを永続化するためのボリューム
      - ./models:/workspace/models
      # Hugging Faceキャッシュ
      - ./.cache:/root/.cache
      # フロントエンド（開発時に即座に反映）
      - ./frontend:/workspace/frontend
    ports:
      - "8080:8080"
    # 統合プロキシサーバーを起動
    command: >
      /bin/bash -c "uvicorn proxy_server:app --host 0.0.0.0 --port 8080"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
