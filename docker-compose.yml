services:
  vllm-server:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: vllm-gb10
    restart: unless-stopped
    shm_size: 16g
    ipc: host
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      # モデルを永続化するためのボリューム
      - ./models:/workspace/models
      # Hugging Faceキャッシュ
      - ./.cache:/root/.cache
    ports:
      - "8001:8000"
    # FastAPIサーバーを起動
    command: >
      /bin/bash -c "uvicorn server:app --host 0.0.0.0 --port 8000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
